---
pubDate: 2025-10-15
team: "fluvia-team"
title: When the Computer Stops Being the Bottleneck - AI, Customisation, and the New Division of Labour
description: "How generative AI reshapes enterprise software by letting users customise behaviour through language, and why Fluvial’s CEL-based design fits the AI-assisted future."
image:
  url: "/src/images/blog/10.jpg"
  alt: "Who is in control of the computer now?"
tags: 
  - AI
-----


## When the Computer Stops Being the Bottleneck: AI, Customisation, and the New Division of Labour  

For half a century we have trained people to adapt to computers.  
We clicked where the system allowed, filled in the fields provided, and accepted configuration menus as the limits of what could be done.  The price of reliability was rigidity: software worked because it was predictable, and it was predictable because users had very little room to change it.  

That bargain is beginning to shift.  With the rise of generative and “agentic” AI, ordinary users can now *instruct* computers rather than merely *use* them.  The line between configuration and programming is blurring, and systems that embrace this shift will feel less like locked boxes and more like collaborators.  

### From low-code to language models  

The last decade’s answer to flexibility was the “low-code” platform.  It promised drag-and-drop logic for non-developers — a commendable idea, but one that often produced fragile, opaque systems.  Low-code tools moved complexity from syntax to interface, not away altogether.  

Large Language Models change the equation.  Instead of hiding code behind diagrams, they allow code to be generated, explained and modified in ordinary language.  A non-programmer can now ask an AI assistant to “route high-risk vendors to the legal team if the score is under 60”, and receive a functioning snippet of policy logic in response.  The machine writes the expression; the human verifies intent.  

What emerges is a new balance of labour: humans supply context and judgement, AI handles translation and syntax.  

### The waterbed theory of complexity  

Fluvial’s design starts from an unglamorous truth: complexity never disappears, it only moves.  Push it down in one place and it bulges up in another — like a waterbed.  Traditional enterprise systems bury complexity inside configuration screens and boolean switches.  They are “simple” only in the sense that the user cannot see the machinery.  

Fluvial takes the opposite approach.  It exposes control through a compact, well-defined expression language — **CEL** — at key decision points: who can view what, when a workflow advances, how scores are calculated, what triggers an integration.  That makes the platform honest about where complexity lives.  You can bend the rules, but you can also see them.  

Until recently, such openness would have been intimidating.  Writing expressions, even short ones, demanded technical skill and documentation.  The difference now is that generative AI can shoulder that work.  The user can ask, “write a CEL rule that blocks approval unless both finance and security have signed off”, and the system (or a connected assistant) can supply it instantly.  The result is still human-legible, still auditable, but far less forbidding.  

### Designing for an AI-assisted world  

Building systems that genuinely benefit from AI requires more than grafting a chatbot onto the front end.  A few architectural principles make the difference:  

1. **Everything addressable by API** – AI agents need real interfaces, not simulated clicks.  An API-first platform lets an agent read, write and orchestrate safely.  
2. **Expression points, not configuration forests** – give AI concise, declarative surfaces to work with.  Expression languages such as CEL are perfect for this: bounded in scope, strongly typed, and easy to audit.  
3. **Clear semantics and documentation** – the model must understand what each endpoint and field *means*; ambiguity breeds errors.  OpenAPI definitions and JSON Schemas provide that clarity.  
4. **Security boundaries** – when AI gains the ability to act, not just advise, permissions and logging become essential.  Every agent call should be as accountable as a human one.  
5. **Composable automation** – event systems and webhooks allow AI components to fit into existing workflows rather than replace them wholesale.  

Fluvial’s integration architecture was built with these ideas from the outset.  Because every capability is API-exposed and every decision point can be controlled through CEL, the system is inherently “AI-ready”.  An agent can read a questionnaire, analyse responses, draft policies, or trigger next-stage workflows without human re-keying.  Yet humans remain firmly in charge of logic and oversight.  

### Collaboration, not delegation  

The deeper opportunity here is cultural rather than technical.  As AI systems become collaborators, organisations must decide how much discretion to grant them and how to capture the reasoning behind automated decisions.  Expression languages help precisely because they make those decisions explicit.  Instead of a hidden neural model deciding what “high risk” means, a CEL rule states it plainly.  Transparency becomes the new usability.  

In this sense, AI doesn’t so much replace humans as *upgrade* them.  The compliance analyst who once clicked through configuration pages can now shape system behaviour directly, using natural language to generate rules that encode policy intent.  The computer executes; the human curates.  

### Towards the next generation of enterprise tools  

If the 2010s were about workflow automation, the 2020s will be about *behavioural customisation* — software that can be taught, not merely configured.  The winners will be systems that strike the right balance between expressiveness and safety: open enough for AI to act, disciplined enough for humans to trust.  

Fluvial’s choice to embed CEL rather than a full programming language reflects that balance.  It avoids turning the platform into a spaghetti of toggles, but it also respects the complexity of real-world governance.  AI simply makes that trade-off workable at last, by generating and explaining the rules that would once have required a specialist.  

The result is a quieter revolution: not computers replacing people, but people finally able to speak to computers in their own language — and be understood.  
